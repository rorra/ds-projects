{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba60ac18",
   "metadata": {},
   "source": [
    "# Natural Language Processing with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bc8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Setup gpu drivers\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0098c1",
   "metadata": {},
   "source": [
    "The main goal of natural language processing (NLP) is to derive information from natural language.\n",
    "\n",
    "* Text\n",
    "* Speech\n",
    "\n",
    "> Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73b32c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-09 21:15:09--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2800:3f0:4004:80a::2010, 2800:3f0:4004:80b::2010, 2800:3f0:4004:810::2010, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2800:3f0:4004:80a::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 607343 (593K) [application/zip]\n",
      "Saving to: ‘nlp_getting_started.zip.1’\n",
      "\n",
      "nlp_getting_started 100%[===================>] 593,11K   844KB/s    in 0,7s    \n",
      "\n",
      "2023-07-09 21:15:10 (844 KB/s) - ‘nlp_getting_started.zip.1’ saved [607343/607343]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download data (same as from Kaggle)\n",
    "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695066ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c31da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip data\n",
    "unzip_data(\"nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ebaf3",
   "metadata": {},
   "source": [
    "Unzipping `nlp_getting_started.zip` gives the following 3 .csv files:\n",
    "\n",
    "- `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
    "- `train.csv` - training samples of real and not real diaster Tweets.\n",
    "- `test.csv` - testing samples of real and not real diaster Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbbaca5",
   "metadata": {},
   "source": [
    "### Visualizing a text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711d8476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0e31ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7ed03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test data doesn't have a target (that's what we'd try to predict)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60eaa6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d72a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples: 3263\n",
      "Total samples: 10876\n"
     ]
    }
   ],
   "source": [
    "# How many samples total?\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab38c097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Remove the http://t.co/9Jxb3rx8mF and Linkury Browser Hijacker http://t.co/B5s5epJ7Um http://t.co/hPA9GQRyWa\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "According to a 2011 Gallup poll the more money you have the more likely you are to suffer from time famine.? AriÛ_ http://t.co/QdmVTJ4lZJ\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@4Tiles @ZacB_ my dell tablet screams with win10\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "The Latest: More homes razed by Northern California wildfire - http://t.co/2nIP3d15dx http://t.co/egYFNlAOQv\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "DK Eyewitness Travel Guide: Denmark: travel guide eBay auctions you should keep an eye on: http://t.co/qPUr3Vd7Hl\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5)\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb76128",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d40f58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1, # dedicate 10% of samples to validation set\n",
    "    random_state=42 # random state for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307fc075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310282f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871799c",
   "metadata": {},
   "source": [
    "### Converting text into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f6697",
   "metadata": {},
   "source": [
    "In NLP, there are two main concepts for turning text into numbers:\n",
    "\n",
    "- **Tokenization** - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
    "    1. **Word-level tokenization**, with the sentence \"I love TensorFlow\" might result in \"I\" being `0`, \"love\" being `1` and \"TensorFlow\" being `2`. In this case, every word in a sequence considered a single token.\n",
    "    2. **Character-level tokenization**, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
    "    3. **Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
    "- **Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
    "    1. **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
    "    2. **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a1e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a70ed182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 21:15:10.987070: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-09 21:15:10.987659: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: \n"
     ]
    }
   ],
   "source": [
    "# Use the default TextVectorization variables\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "    split=\"whitespace\", # how to split tokens\n",
    "    ngrams=None, # create groups of n-words?\n",
    "    output_mode=\"int\", # how to map tokens to numbers\n",
    "    output_sequence_length=None, # how long should the output sequence of tokens be?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53fc76c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d851384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bd9881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "561b1a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "171c0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Police respond to crash find 'suspected heroin' http://t.co/oJoecW29qa      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[  77, 1776,    5,   85,  653, 1355, 5487,    1,    0,    0,    0,\n",
       "           0,    0,    0,    0]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80fca215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f722d",
   "metadata": {},
   "source": [
    "### Creating an Embedding using an Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14cd7dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x7f7de55df970>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length, # set input shape\n",
    "    output_dim=128, # set size of embedding vector\n",
    "    embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "    input_length=max_length, # how long is each input\n",
    "    name=\"embedding_1\"\n",
    ") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b75f6418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "FYI: ;ACCIDENT PROPERTY DAMAGE;3460 LIMESTONE LN;COL;YELLOWSTONE WAY;FIELDSTONE DR;08/05/2015 19:36:35      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.02302963,  0.04713346, -0.04361195, ..., -0.02888709,\n",
       "         -0.00325148, -0.04196633],\n",
       "        [-0.03687047,  0.01454656, -0.03870597, ..., -0.04347464,\n",
       "         -0.00051489, -0.04295359],\n",
       "        [ 0.04344462, -0.00343281,  0.04108752, ..., -0.03313749,\n",
       "         -0.00628723,  0.01452018],\n",
       "        ...,\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097],\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097],\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab360357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-0.02302963,  0.04713346, -0.04361195, -0.01639892, -0.0110131 ,\n",
       "       -0.04619982,  0.04648959, -0.0437777 , -0.01139256,  0.02103316,\n",
       "        0.04973144, -0.04313646,  0.01160907, -0.03791947, -0.03483901,\n",
       "        0.04946733,  0.0015441 ,  0.00566403,  0.02486538,  0.00015681,\n",
       "        0.03624806, -0.04378878,  0.03039742,  0.01690355, -0.0022974 ,\n",
       "        0.01481581, -0.01697095,  0.04612421,  0.02441675, -0.01247214,\n",
       "       -0.03715664,  0.01793149, -0.00878384,  0.0172084 ,  0.01127325,\n",
       "       -0.01159786, -0.01547537,  0.03706814, -0.02825143,  0.03123552,\n",
       "       -0.03697674, -0.02677993,  0.03393617, -0.00548829,  0.00784463,\n",
       "       -0.02412388, -0.04068184, -0.04705523, -0.02094219, -0.02399762,\n",
       "       -0.02940009,  0.04210461, -0.00632124, -0.04347691, -0.00900681,\n",
       "       -0.02897203, -0.03138303, -0.01261019, -0.00845705, -0.04783287,\n",
       "        0.04288604,  0.04916037, -0.01700062,  0.00671352,  0.00769603,\n",
       "        0.04907951, -0.04658123,  0.048005  , -0.01213558,  0.03595922,\n",
       "        0.01974065, -0.0200804 , -0.02066579, -0.03743062, -0.01847623,\n",
       "        0.03713388,  0.0245539 , -0.03882917,  0.03494865,  0.00956715,\n",
       "        0.03404409,  0.011621  ,  0.01881218, -0.01327131,  0.03119954,\n",
       "        0.00610849,  0.03852627,  0.0278471 ,  0.00850505, -0.00783464,\n",
       "       -0.02777647,  0.00506955, -0.02553365, -0.02769493,  0.0124807 ,\n",
       "       -0.01926706, -0.00874001,  0.00744513,  0.04392729, -0.01591187,\n",
       "       -0.00074472,  0.00414648, -0.02875608, -0.01474787, -0.02719539,\n",
       "        0.00559096,  0.02336929, -0.03689684,  0.04367295,  0.01930216,\n",
       "        0.03147853,  0.02734116,  0.04280826,  0.00270581,  0.01501298,\n",
       "       -0.00610001,  0.03428786, -0.00413691,  0.02679456,  0.03581288,\n",
       "       -0.03631062,  0.02236429,  0.00414394, -0.01636294,  0.02442387,\n",
       "       -0.02888709, -0.00325148, -0.04196633], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0e7b1",
   "metadata": {},
   "source": [
    "### Modelling a text dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079736b6",
   "metadata": {},
   "source": [
    "- **Model 0**: Naive Bayes (baseline)\n",
    "- **Model 1**: Feed-forward neural network (dense model)\n",
    "- **Model 2**: LSTM model\n",
    "- **Model 3**: GRU model\n",
    "- **Model 4**: Bidirectional-LSTM model\n",
    "- **Model 5**: 1D Convolutional Neural Network\n",
    "- **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
    "- **Model 7**: Same as model 6 with 10% of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3b3c5",
   "metadata": {},
   "source": [
    "### Model 0: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4c8b97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # Convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) # Model the text\n",
    "])\n",
    "\n",
    "# fit the pipeline to the training set\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba5cb551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f97f5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb37bb0",
   "metadata": {},
   "source": [
    "#### Creating an evaluation function for our model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b9bc248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    y_true = true labels in the form of a 1D array\n",
    "    y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "    Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1\n",
    "    }\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3546e5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_preds\n",
    ")\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d1283",
   "metadata": {},
   "source": [
    "### Model 1: A simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1277fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb2b6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\") # Input is 1 dimensional string\n",
    "x = text_vectorizer(inputs) # Input into numbers\n",
    "x = embedding(x) # Embedding of the numeric values\n",
    "x = layers.GlobalAveragePooling1D()(x) # Lower the dimensionality of the embedding\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Output layer, with binary output\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c718e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6de1ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7025bfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20230709-214349\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[\n",
    "        create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name=\"simple_dense_model\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db7fac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 574us/step - loss: 0.4767 - accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4766846001148224, 0.787401556968689]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29af4d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
       " array([[ 0.00073164,  0.01504796, -0.03425452, ..., -0.0440354 ,\n",
       "         -0.01042278,  0.01876435],\n",
       "        [ 0.04135865, -0.03945084, -0.03811938, ...,  0.00464736,\n",
       "          0.03163553,  0.02928305],\n",
       "        [ 0.00684033,  0.05363134, -0.00241555, ..., -0.07082178,\n",
       "         -0.04750701,  0.01448254],\n",
       "        ...,\n",
       "        [-0.03301444, -0.0052493 , -0.04209725, ...,  0.02028764,\n",
       "          0.00308807,  0.02215792],\n",
       "        [ 0.00692342,  0.05942352, -0.01975194, ..., -0.06199061,\n",
       "         -0.01018394,  0.0351042 ],\n",
       "        [-0.0372346 ,  0.06267188, -0.07451146, ..., -0.02367217,\n",
       "         -0.08643329,  0.01742155]], dtype=float32)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65cf3a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f860c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/RJ72DuGBRHKn18KH9YXZSg/\n",
      "\n",
      "\u001b[1m[2023-07-09T21:45:05]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2023-07-09T21:45:07]\u001b[0m Total uploaded: 30 scalars, 0 tensors, 1 binary objects (63.0 kB)\n",
      "\u001b[1m[2023-07-09T21:45:07]\u001b[0m Done scanning logdir.\n",
      "\n",
      "\n",
      "Done. View your TensorBoard at https://tensorboard.dev/experiment/RJ72DuGBRHKn18KH9YXZSg/\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir ./model_logs \\\n",
    "    --name \"First deep model on text data\" \\\n",
    "    --description \"Trying a dense model with an embedding layer\" \\\n",
    "    --one_shot # exits the uploader when upload has finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "075d5998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted experiment RJ72DuGBRHKn18KH9YXZSg.\r\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev delete --experiment_id RJ72DuGBRHKn18KH9YXZSg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b057a973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 470us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.404882  ],\n",
       "       [0.7443312 ],\n",
       "       [0.997895  ],\n",
       "       [0.1089    ],\n",
       "       [0.1114353 ],\n",
       "       [0.9355609 ],\n",
       "       [0.9134594 ],\n",
       "       [0.99253446],\n",
       "       [0.9715681 ],\n",
       "       [0.2657034 ]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba88c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49514ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.74015748031496,\n",
       " 'precision': 0.7914920592553047,\n",
       " 'recall': 0.7874015748031497,\n",
       " 'f1': 0.7846966492209201}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels, \n",
    "    y_pred=model_1_preds\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7e5485e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0dc98ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
     ]
    }
   ],
   "source": [
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "    for key, value in baseline_results.items():\n",
    "        print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(\n",
    "    baseline_results=baseline_results, \n",
    "    new_model_results=model_1_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7682d05",
   "metadata": {},
   "source": [
    "#### Visualizing learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "554e68be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0242a85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6729cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer \n",
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12a69884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
    "import io\n",
    "\n",
    "# Create output writers\n",
    "out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
    "out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# Write embedding vectors and words to file\n",
    "for num, word in enumerate(words_in_vocab):\n",
    "    if num == 0: \n",
    "        continue # skip padding token\n",
    "    vec = embed_weights[num]\n",
    "    out_m.write(word + \"\\n\") # write words to file\n",
    "    out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "# Download files locally to upload to Embedding Projector\n",
    "try:\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "    pass\n",
    "else:\n",
    "    files.download(\"embedding_vectors.tsv\")\n",
    "    files.download(\"embedding_metadata.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb583ef",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks (RNN's)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df6050",
   "metadata": {},
   "source": [
    "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
    "\n",
    "Recurrent neural networks can be used for a number of sequence-based problems:\n",
    "- **One to one**: one input, one output, such as image classification.\n",
    "- **One to many**: one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
    "- **Many to one**: many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
    "- **Many to many**: many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd4248b",
   "metadata": {},
   "source": [
    "### Model 2: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0ad49bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_2_embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    input_length=max_length,\n",
    "    name=\"embedding_2\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a76ae424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3f11753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb27f703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/LSTM/20230709-220710\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 15ms/step - loss: 0.5100 - accuracy: 0.7416 - val_loss: 0.4566 - val_accuracy: 0.7822\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.3176 - accuracy: 0.8717 - val_loss: 0.5138 - val_accuracy: 0.7756\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.5858 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.6041 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8746 - val_accuracy: 0.7507\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[\n",
    "        create_tensorboard_callback(SAVE_DIR, \"LSTM\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6863069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.00712613],\n",
       "        [0.78736913],\n",
       "        [0.99963766],\n",
       "        [0.05679176],\n",
       "        [0.0025822 ],\n",
       "        [0.9996238 ],\n",
       "        [0.92170185],\n",
       "        [0.9997993 ],\n",
       "        [0.99949545],\n",
       "        [0.6645746 ]], dtype=float32))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4f06716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "622b0fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.06561679790026,\n",
       " 'precision': 0.7510077975908164,\n",
       " 'recall': 0.7506561679790026,\n",
       " 'f1': 0.7489268622514025}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_2_preds\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6f4fa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 75.07, Difference: -4.20\n",
      "Baseline precision: 0.81, New precision: 0.75, Difference: -0.06\n",
      "Baseline recall: 0.79, New recall: 0.75, Difference: -0.04\n",
      "Baseline f1: 0.79, New f1: 0.75, Difference: -0.04\n"
     ]
    }
   ],
   "source": [
    "# Compare model 2 to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dca7ec",
   "metadata": {},
   "source": [
    "### Model 3: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3da9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_3_embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    input_length=max_length,\n",
    "    name=\"embedding_3\"\n",
    ")\n",
    "\n",
    "# Build an RNN using the GRU cell\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
    "x = layers.GRU(64)(x) \n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "968ac0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile GRU model\n",
    "model_3.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "acb7a5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b62ba3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/GRU/20230709-221155\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 16ms/step - loss: 0.5242 - accuracy: 0.7314 - val_loss: 0.4553 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.3195 - accuracy: 0.8694 - val_loss: 0.4937 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.2197 - accuracy: 0.9181 - val_loss: 0.5607 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.1599 - accuracy: 0.9441 - val_loss: 0.6220 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.1221 - accuracy: 0.9584 - val_loss: 0.6205 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_3_history = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14b36b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.33325186],\n",
       "        [0.8774119 ],\n",
       "        [0.9980251 ],\n",
       "        [0.11561717],\n",
       "        [0.01235959],\n",
       "        [0.9925638 ],\n",
       "        [0.6214276 ],\n",
       "        [0.9981333 ],\n",
       "        [0.9982377 ],\n",
       "        [0.5018121 ]], dtype=float32))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation data\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs.shape, model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c9fffad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to prediction classes\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c4efe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 0.7675450859410361,\n",
       " 'recall': 0.7677165354330708,\n",
       " 'f1': 0.7667932666650168}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuate model_3 results\n",
    "model_3_results = calculate_results(\n",
    "    y_true=val_labels, \n",
    "    y_pred=model_3_preds\n",
    ")\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c449bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d9070f",
   "metadata": {},
   "source": [
    "### Model 4: Bidirectonal RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "081e3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_4_embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    input_length=max_length,\n",
    "    name=\"embedding_4\"\n",
    ")\n",
    "\n",
    "# Build a Bidirectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75b1c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_4.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c7c69aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of our bidirectional model\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "976b0326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20230709-221415\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 20ms/step - loss: 0.5093 - accuracy: 0.7481 - val_loss: 0.4606 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.3135 - accuracy: 0.8708 - val_loss: 0.5144 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.5626 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.1523 - accuracy: 0.9469 - val_loss: 0.6365 - val_accuracy: 0.7769\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.6509 - val_accuracy: 0.7664\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (takes longer because of the bidirectional layers)\n",
    "model_4_history = model_4.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f9d818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04000106],\n",
       "       [0.8279268 ],\n",
       "       [0.99842227],\n",
       "       [0.13531172],\n",
       "       [0.00311334],\n",
       "       [0.99220747],\n",
       "       [0.9552847 ],\n",
       "       [0.9994564 ],\n",
       "       [0.99898285],\n",
       "       [0.28141788]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with bidirectional RNN on the validation data\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a8d088e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06c347f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.64041994750657,\n",
       " 'precision': 0.7665895370389821,\n",
       " 'recall': 0.7664041994750657,\n",
       " 'f1': 0.7651213533864446}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate bidirectional RNN model results\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1650be56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.64, Difference: -2.62\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Check to see how the bidirectional model performs against the baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18752def",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks for Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28408079",
   "metadata": {},
   "source": [
    "### Model 5: Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76a7872f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the embedding, 1D convolutional and max pooling\n",
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
    "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
    "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
    "max_pool = layers.GlobalMaxPool1D() \n",
    "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb20bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       " array([[[ 0.02534915, -0.03109056,  0.00285618, ..., -0.00783163,\n",
       "          -0.02685576, -0.04434135],\n",
       "         [-0.0658626 ,  0.09451497, -0.01477603, ..., -0.00657783,\n",
       "          -0.0423879 ,  0.07777893],\n",
       "         [-0.04803649, -0.00709754, -0.02330892, ..., -0.01807335,\n",
       "           0.02351036,  0.02676385],\n",
       "         ...,\n",
       "         [ 0.00073164,  0.01504796, -0.03425452, ..., -0.0440354 ,\n",
       "          -0.01042278,  0.01876435],\n",
       "         [ 0.00073164,  0.01504796, -0.03425452, ..., -0.0440354 ,\n",
       "          -0.01042278,  0.01876435],\n",
       "         [ 0.00073164,  0.01504796, -0.03425452, ..., -0.0440354 ,\n",
       "          -0.01042278,  0.01876435]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
       " array([[[0.08324983, 0.00648711, 0.        , 0.03983572, 0.        ,\n",
       "          0.01144424, 0.00416248, 0.02288384, 0.        , 0.00900974,\n",
       "          0.        , 0.        , 0.03401766, 0.06408261, 0.08103721,\n",
       "          0.00409015, 0.01579617, 0.        , 0.07930174, 0.        ,\n",
       "          0.        , 0.        , 0.14525086, 0.        , 0.        ,\n",
       "          0.        , 0.03682068, 0.06534288, 0.        , 0.        ,\n",
       "          0.0509464 , 0.        ],\n",
       "         [0.        , 0.05387186, 0.        , 0.11491334, 0.        ,\n",
       "          0.        , 0.16237089, 0.        , 0.        , 0.00171234,\n",
       "          0.14336716, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.01197943, 0.        , 0.        , 0.13551353, 0.0040105 ,\n",
       "          0.10309848, 0.09445541, 0.08390274, 0.        , 0.04213045,\n",
       "          0.04487598, 0.06560446, 0.        , 0.02272679, 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.03683234, 0.04895752, 0.        , 0.15324767, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.04650328, 0.00496452, 0.07349388, 0.01608636,\n",
       "          0.        , 0.02779123, 0.        , 0.08080547, 0.01403156,\n",
       "          0.        , 0.03768801, 0.10382751, 0.        , 0.03361669,\n",
       "          0.        , 0.02577581, 0.00140341, 0.        , 0.        ,\n",
       "          0.03211506, 0.        ],\n",
       "         [0.00887842, 0.10450958, 0.        , 0.06974545, 0.02328693,\n",
       "          0.        , 0.04052216, 0.        , 0.        , 0.02733746,\n",
       "          0.08674355, 0.        , 0.        , 0.06129849, 0.02007272,\n",
       "          0.        , 0.        , 0.        , 0.0336425 , 0.        ,\n",
       "          0.04525371, 0.05219691, 0.06375685, 0.        , 0.        ,\n",
       "          0.0077441 , 0.00273444, 0.        , 0.        , 0.0049965 ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.02369051, 0.        , 0.0582763 , 0.05297653,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.01719731, 0.02936819, 0.00466111, 0.06879899, 0.01944811,\n",
       "          0.01585553, 0.01294557, 0.        , 0.0686651 , 0.        ,\n",
       "          0.00623799, 0.03514038, 0.02407503, 0.        , 0.05979814,\n",
       "          0.        , 0.01170123, 0.        , 0.        , 0.        ,\n",
       "          0.0444493 , 0.        ],\n",
       "         [0.03544891, 0.        , 0.        , 0.05054992, 0.06105449,\n",
       "          0.        , 0.00997432, 0.01403011, 0.        , 0.01680711,\n",
       "          0.03148524, 0.03889378, 0.        , 0.07710698, 0.00590965,\n",
       "          0.        , 0.00263046, 0.        , 0.08935819, 0.        ,\n",
       "          0.        , 0.05331142, 0.05227915, 0.        , 0.06658381,\n",
       "          0.01881717, 0.02448675, 0.        , 0.        , 0.        ,\n",
       "          0.02008449, 0.        ],\n",
       "         [0.03544891, 0.        , 0.        , 0.05054992, 0.06105449,\n",
       "          0.        , 0.00997432, 0.01403011, 0.        , 0.01680711,\n",
       "          0.03148524, 0.03889378, 0.        , 0.07710698, 0.00590965,\n",
       "          0.        , 0.00263046, 0.        , 0.08935819, 0.        ,\n",
       "          0.        , 0.05331142, 0.05227915, 0.        , 0.06658381,\n",
       "          0.01881717, 0.02448675, 0.        , 0.        , 0.        ,\n",
       "          0.02008449, 0.        ],\n",
       "         [0.03544891, 0.        , 0.        , 0.05054992, 0.06105449,\n",
       "          0.        , 0.00997432, 0.01403011, 0.        , 0.01680711,\n",
       "          0.03148524, 0.03889378, 0.        , 0.07710698, 0.00590965,\n",
       "          0.        , 0.00263046, 0.        , 0.08935819, 0.        ,\n",
       "          0.        , 0.05331142, 0.05227915, 0.        , 0.06658381,\n",
       "          0.01881717, 0.02448675, 0.        , 0.        , 0.        ,\n",
       "          0.02008449, 0.        ],\n",
       "         [0.03544891, 0.        , 0.        , 0.05054992, 0.06105449,\n",
       "          0.        , 0.00997432, 0.01403011, 0.        , 0.01680711,\n",
       "          0.03148524, 0.03889378, 0.        , 0.07710698, 0.00590965,\n",
       "          0.        , 0.00263046, 0.        , 0.08935819, 0.        ,\n",
       "          0.        , 0.05331142, 0.05227915, 0.        , 0.06658381,\n",
       "          0.01881717, 0.02448675, 0.        , 0.        , 0.        ,\n",
       "          0.02008449, 0.        ],\n",
       "         [0.03544891, 0.        , 0.        , 0.05054992, 0.06105449,\n",
       "          0.        , 0.00997432, 0.01403011, 0.        , 0.01680711,\n",
       "          0.03148524, 0.03889378, 0.        , 0.07710698, 0.00590965,\n",
       "          0.        , 0.00263046, 0.        , 0.08935819, 0.        ,\n",
       "          0.        , 0.05331142, 0.05227915, 0.        , 0.06658381,\n",
       "          0.01881717, 0.02448675, 0.        , 0.        , 0.        ,\n",
       "          0.02008449, 0.        ],\n",
       "         [0.03544891, 0.        , 0.        , 0.05054992, 0.06105449,\n",
       "          0.        , 0.00997432, 0.01403011, 0.        , 0.01680711,\n",
       "          0.03148524, 0.03889378, 0.        , 0.07710698, 0.00590965,\n",
       "          0.        , 0.00263046, 0.        , 0.08935819, 0.        ,\n",
       "          0.        , 0.05331142, 0.05227915, 0.        , 0.06658381,\n",
       "          0.01881717, 0.02448675, 0.        , 0.        , 0.        ,\n",
       "          0.02008449, 0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       " array([[0.08324983, 0.10450958, 0.        , 0.15324767, 0.06105449,\n",
       "         0.01144424, 0.16237089, 0.02288384, 0.        , 0.02733746,\n",
       "         0.14336716, 0.04650328, 0.03401766, 0.07710698, 0.08103721,\n",
       "         0.01585553, 0.02779123, 0.        , 0.13551353, 0.01403156,\n",
       "         0.10309848, 0.09445541, 0.14525086, 0.        , 0.06658381,\n",
       "         0.04487598, 0.06560446, 0.06534288, 0.02272679, 0.0049965 ,\n",
       "         0.0509464 , 0.        ]], dtype=float32)>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the outputs of each layer\n",
    "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63d91290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_5_embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    input_length=max_length,\n",
    "    name=\"embedding_5\"\n",
    ")\n",
    "\n",
    "# Create 1-dimensional convolutional layer to model sequences\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
    "\n",
    "# Compile Conv1D model\n",
    "model_5.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Get a summary of our 1D convolution model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a4b61a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Conv1D/20230709-221710\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.5652 - accuracy: 0.7141 - val_loss: 0.4733 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.3380 - accuracy: 0.8615 - val_loss: 0.4758 - val_accuracy: 0.7730\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.2070 - accuracy: 0.9234 - val_loss: 0.5457 - val_accuracy: 0.7730\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1314 - accuracy: 0.9578 - val_loss: 0.6163 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0933 - accuracy: 0.9691 - val_loss: 0.6779 - val_accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"Conv1D\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4c3d952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.22534512],\n",
       "       [0.7534111 ],\n",
       "       [0.99956024],\n",
       "       [0.05562783],\n",
       "       [0.01449854],\n",
       "       [0.98585176],\n",
       "       [0.98418933],\n",
       "       [0.99758804],\n",
       "       [0.9986262 ],\n",
       "       [0.26914346]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_5\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3a896a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_5 prediction probabilities to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c6644c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'precision': 0.7807522349051432,\n",
       " 'recall': 0.7782152230971129,\n",
       " 'f1': 0.7758810170952618}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_5 evaluation metrics \n",
    "model_5_results = calculate_results(\n",
    "    y_true=val_labels, \n",
    "    y_pred=model_5_preds\n",
    ")\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09fc334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.82, Difference: -1.44\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
      "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
      "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
     ]
    }
   ],
   "source": [
    "# Compare model_5 results to baseline \n",
    "compare_baseline_to_new_results(baseline_results, model_5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a7b12",
   "metadata": {},
   "source": [
    "### Using Pretrained Embeddings (transfer learning for NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b52d9e",
   "metadata": {},
   "source": [
    "### Model 6: TensorFlow Hub Pretrained Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5c89863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01157025  0.02485911  0.02878051 -0.012715    0.03971541  0.08827761\n",
      "  0.02680988  0.05589838 -0.01068731 -0.00597293  0.00639321 -0.01819516\n",
      "  0.00030816  0.09105889  0.05874645 -0.03180629  0.01512474 -0.05162925\n",
      "  0.00991366 -0.06865345 -0.04209306  0.0267898   0.03011009  0.00321065\n",
      " -0.00337968 -0.04787356  0.0226672  -0.00985927 -0.04063615 -0.01292093\n",
      " -0.04666382  0.05630299 -0.03949255  0.00517682  0.02495827 -0.07014439\n",
      "  0.0287151   0.0494768  -0.00633978 -0.08960193  0.02807119 -0.00808364\n",
      " -0.01360601  0.05998649 -0.10361788 -0.05195372  0.00232958 -0.02332531\n",
      " -0.03758106  0.03327729], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
    "embed_samples = embed(\n",
    "    [sample_sentence, \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"]\n",
    ")\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5bf276ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each sentence has been encoded into a 512 dimension vector\n",
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f8c51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "    input_shape=[], # shape of inputs coming to our model \n",
    "    dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "    trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
    "    name=\"USE\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9cb81ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile model\n",
    "model_6.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7cd3faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20230709-222156\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 8ms/step - loss: 0.5008 - accuracy: 0.7892 - val_loss: 0.4478 - val_accuracy: 0.7966\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.4144 - accuracy: 0.8133 - val_loss: 0.4369 - val_accuracy: 0.8058\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.4329 - val_accuracy: 0.8110\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3925 - accuracy: 0.8266 - val_loss: 0.4288 - val_accuracy: 0.8110\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.3860 - accuracy: 0.8276 - val_loss: 0.4309 - val_accuracy: 0.8123\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"tf_hub_sentence_encoder\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc0d7ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14443198],\n",
       "       [0.7271504 ],\n",
       "       [0.9856655 ],\n",
       "       [0.19740926],\n",
       "       [0.73417026],\n",
       "       [0.6859663 ],\n",
       "       [0.9808888 ],\n",
       "       [0.9741102 ],\n",
       "       [0.91573215],\n",
       "       [0.08070083]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0e07e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee73766b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.23359580052494,\n",
       " 'precision': 0.8148798668657973,\n",
       " 'recall': 0.8123359580052494,\n",
       " 'f1': 0.810686575717776}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "20035ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 81.23, Difference: 1.97\n",
      "Baseline precision: 0.81, New precision: 0.81, Difference: 0.00\n",
      "Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n",
      "Baseline f1: 0.79, New f1: 0.81, Difference: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare TF Hub model to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_6_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590be92c",
   "metadata": {},
   "source": [
    "### Model 7: TensorFlow Hub Pretrained Sentence Encoder 10% of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d507458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 6851\n",
      "Length of 10% training examples: 686\n"
     ]
    }
   ],
   "source": [
    "# (split the already split train_sentences/train_labels)\n",
    "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(\n",
    "    np.array(train_sentences),\n",
    "    train_labels,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Check length of 10 percent datasets\n",
    "print(f\"Total training examples: {len(train_sentences)}\")\n",
    "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1a5664c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    415\n",
       "1    271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_labels_10_percent).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38a16bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Clone model_6 but reset weights\n",
    "model_7 = tf.keras.models.clone_model(model_6)\n",
    "\n",
    "# Compile model\n",
    "model_7.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Get a summary (will be same as model_6)\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e96d66d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20230709-222435\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 31ms/step - loss: 0.6716 - accuracy: 0.6574 - val_loss: 0.6526 - val_accuracy: 0.6903\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5972 - accuracy: 0.8032 - val_loss: 0.5944 - val_accuracy: 0.7362\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.5178 - accuracy: 0.8149 - val_loss: 0.5398 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.4526 - accuracy: 0.8265 - val_loss: 0.5084 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.4094 - accuracy: 0.8382 - val_loss: 0.4915 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to 10% of the training data\n",
    "model_7_history = model_7.fit(\n",
    "    x=train_sentences_10_percent,\n",
    "    y=train_labels_10_percent,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "222c8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.24043253],\n",
       "       [0.7683783 ],\n",
       "       [0.9013718 ],\n",
       "       [0.2906796 ],\n",
       "       [0.57149965],\n",
       "       [0.8356513 ],\n",
       "       [0.80629426],\n",
       "       [0.83358157],\n",
       "       [0.85545665],\n",
       "       [0.11749935]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the model trained on 10% of the data\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d981e87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2445e903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7755630249535594,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1': 0.7667059443150692}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model results\n",
    "model_7_results = calculate_results(val_labels, model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "76dabc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
      "Baseline precision: 0.81, New precision: 0.78, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_7_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a9d68",
   "metadata": {},
   "source": [
    "### Comparing the performance of each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e5937e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>78.740157</td>\n",
       "      <td>0.791492</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.784697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>75.065617</td>\n",
       "      <td>0.751008</td>\n",
       "      <td>0.750656</td>\n",
       "      <td>0.748927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>76.771654</td>\n",
       "      <td>0.767545</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.766793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>76.640420</td>\n",
       "      <td>0.766590</td>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.765121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>77.821522</td>\n",
       "      <td>0.780752</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.775881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>81.233596</td>\n",
       "      <td>0.814880</td>\n",
       "      <td>0.812336</td>\n",
       "      <td>0.810687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.775563</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.766706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                 79.265092   0.811139  0.792651  0.786219\n",
       "simple_dense             78.740157   0.791492  0.787402  0.784697\n",
       "lstm                     75.065617   0.751008  0.750656  0.748927\n",
       "gru                      76.771654   0.767545  0.767717  0.766793\n",
       "bidirectional            76.640420   0.766590  0.766404  0.765121\n",
       "conv1d                   77.821522   0.780752  0.778215  0.775881\n",
       "tf_hub_sentence_encoder  81.233596   0.814880  0.812336  0.810687\n",
       "tf_hub_10_percent_data   77.034121   0.775563  0.770341  0.766706"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\n",
    "    \"baseline\": baseline_results,\n",
    "    \"simple_dense\": model_1_results,\n",
    "    \"lstm\": model_2_results,\n",
    "    \"gru\": model_3_results,\n",
    "    \"bidirectional\": model_4_results,\n",
    "    \"conv1d\": model_5_results,\n",
    "    \"tf_hub_sentence_encoder\": model_6_results,\n",
    "    \"tf_hub_10_percent_data\": model_7_results}\n",
    ")\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fb8b90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "59034d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7cc43dc130>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c60795cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a53370c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/o2ycaFjYREuv5jbDiQAQYw/\n",
      "\n",
      "\u001b[1m[2023-07-09T22:26:41]\u001b[0m Started scanning logdir.\n",
      "\u001b[1m[2023-07-09T22:26:50]\u001b[0m Total uploaded: 210 scalars, 0 tensors, 7 binary objects (2.7 MB)\n",
      "\u001b[1m[2023-07-09T22:26:50]\u001b[0m Done scanning logdir.\n",
      "\n",
      "\n",
      "Done. View your TensorBoard at https://tensorboard.dev/experiment/o2ycaFjYREuv5jbDiQAQYw/\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir ./model_logs \\\n",
    "    --name \"NLP modelling experiments\" \\\n",
    "    --description \"A series of different NLP modellings experiments with various models\" \\\n",
    "    --one_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "891ff475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted experiment o2ycaFjYREuv5jbDiQAQYw.\r\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev delete --experiment_id o2ycaFjYREuv5jbDiQAQYw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044a3eb",
   "metadata": {},
   "source": [
    "### Combining our models (model ensembling/stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86c7ca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get mean pred probs for 3 models\n",
    "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
    "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
    "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
    "combined_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e3258b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.08398950131233,\n",
       " 'precision': 0.7805216999297674,\n",
       " 'recall': 0.7808398950131233,\n",
       " 'f1': 0.7805169025578647}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results from averaging the prediction probabilities\n",
    "ensemble_results = calculate_results(val_labels, combined_preds)\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d0eb27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our combined model's results to the results DataFrame\n",
    "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "481ba5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134787/3504904892.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100\n"
     ]
    }
   ],
   "source": [
    "# Convert the accuracy to the same scale as the rest of the results\n",
    "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bde20be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.791492</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.784697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.750656</td>\n",
       "      <td>0.751008</td>\n",
       "      <td>0.750656</td>\n",
       "      <td>0.748927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.767545</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.766793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.766590</td>\n",
       "      <td>0.766404</td>\n",
       "      <td>0.765121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.780752</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.775881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>0.812336</td>\n",
       "      <td>0.814880</td>\n",
       "      <td>0.812336</td>\n",
       "      <td>0.810687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_10_percent_data</th>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.775563</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.766706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_results</th>\n",
       "      <td>78.083990</td>\n",
       "      <td>0.780522</td>\n",
       "      <td>0.780840</td>\n",
       "      <td>0.780517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                  0.792651   0.811139  0.792651  0.786219\n",
       "simple_dense              0.787402   0.791492  0.787402  0.784697\n",
       "lstm                      0.750656   0.751008  0.750656  0.748927\n",
       "gru                       0.767717   0.767545  0.767717  0.766793\n",
       "bidirectional             0.766404   0.766590  0.766404  0.765121\n",
       "conv1d                    0.778215   0.780752  0.778215  0.775881\n",
       "tf_hub_sentence_encoder   0.812336   0.814880  0.812336  0.810687\n",
       "tf_hub_10_percent_data    0.770341   0.775563  0.770341  0.766706\n",
       "ensemble_results         78.083990   0.780522  0.780840  0.780517"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda000e",
   "metadata": {},
   "source": [
    "### Saving and loading a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a7d39c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a544448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with custom Hub Layer (required with HDF5 format)\n",
    "loaded_model_6 = tf.keras.models.load_model(\n",
    "    \"model_6.h5\", \n",
    "    custom_objects={\"KerasLayer\": hub.KerasLayer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da7780b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.8123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43088313937187195, 0.8123359680175781]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4471e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
     ]
    }
   ],
   "source": [
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0538e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "60c052ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.8123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43088313937187195, 0.8123359680175781]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0dcc4",
   "metadata": {},
   "source": [
    "### Finding the most wrong examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9b056f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.144432\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.727150\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.985666\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0   0.197409\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0   0.734170"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({\n",
    "    \"text\": val_sentences,\n",
    "    \"target\": val_labels,\n",
    "    \"pred\": model_6_preds,\n",
    "    \"pred_prob\": tf.squeeze(model_6_pred_probs)}\n",
    ")\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7d40f7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.910481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.837961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.834874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.782611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.782433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>The Sound of Arson</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "698  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       0   1.0   \n",
       "144                                 The Sound of Arson       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "31    0.910481  \n",
       "759   0.864676  \n",
       "209   0.837961  \n",
       "393   0.836361  \n",
       "628   0.835225  \n",
       "49    0.834874  \n",
       "109   0.800890  \n",
       "251   0.782611  \n",
       "698   0.782433  \n",
       "144   0.771343  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilities\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3ff53401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1, Prob: 0.910480797290802\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8646755218505859\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8379610180854797\n",
      "Text:\n",
      "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8363614678382874\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8352250456809998\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8348744511604309\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.800889790058136\n",
      "Text:\n",
      "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.7826109528541565\n",
      "Text:\n",
      "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.7824330925941467\n",
      "Text:\n",
      "åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.7713427543640137\n",
      "Text:\n",
      "The Sound of Arson\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "for row in most_wrong[:10].itertuples():\n",
    "    _, text, target, pred, prob = row\n",
    "    print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "212ef4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0, Prob: 0.06304336339235306\n",
      "Text:\n",
      "@BoyInAHorsemask its a panda trapped in a dogs body\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06279503554105759\n",
      "Text:\n",
      "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06060810387134552\n",
      "Text:\n",
      "VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP WATCH 241487 http://t.co/yFy3nkkcoH http://t.co/KNEhVvOHVK\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.057317838072776794\n",
      "Text:\n",
      "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.04535556584596634\n",
      "Text:\n",
      "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.04145139828324318\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.03926114737987518\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.0385933518409729\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.03627229481935501\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.03288795426487923\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
    "for row in most_wrong[-10:].itertuples():\n",
    "    _, text, target, pred, prob = row\n",
    "    print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00683e",
   "metadata": {},
   "source": [
    "### Making predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "75ffc3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "Pred: 1, Prob: 0.6204264163970947\n",
      "Text:\n",
      "@JacobHoggard @therealmattleaf  it's so sad out there in BC all the wild fires. Hope u are safe.\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Pred: 1, Prob: 0.9783453941345215\n",
      "Text:\n",
      "Two buildings burn in 3-alarm Antioch fire: Two buildings are burning in a 3-alarm fire at the Delta PinesÛ_ http://t.co/GQgF2ygpX2\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Pred: 0, Prob: 0.0986962541937828\n",
      "Text:\n",
      "lol at the guy whipping by me on a double yellow line in his mustang just to crash on the curb into a light pole #sns\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Pred: 0, Prob: 0.2502424418926239\n",
      "Text:\n",
      "PSA: IÛªm splitting my personalities.\n",
      "\n",
      "?? techies follow @ablaze_co\n",
      "?? Burners follow @ablaze\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Pred: 0, Prob: 0.26033467054367065\n",
      "Text:\n",
      "Obama 2016? - The Abomination of Desolation' http://t.co/iL4uLhrgTP\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Pred: 0, Prob: 0.20710958540439606\n",
      "Text:\n",
      "@rymathieson are you coming to meltdown!\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Pred: 0, Prob: 0.04608171060681343\n",
      "Text:\n",
      "Will Trump obliterate opponents as quick as Rousey?\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Pred: 1, Prob: 0.6867864727973938\n",
      "Text:\n",
      "The EFAK would be designed for building occupants once they evacuate and report to their evacuation assembly sites\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Pred: 0, Prob: 0.0800403505563736\n",
      "Text:\n",
      "I had trouble breathing while listening to kian singing omg\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Pred: 1, Prob: 0.9728121757507324\n",
      "Text:\n",
      "@PieroCastellano @nipped suicide bombing civilians in major TR cities yet?\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "    pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
    "    pred = tf.round(pred_prob)\n",
    "    print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{test_sample}\\n\")\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c36625",
   "metadata": {},
   "source": [
    "### Predicting on Tweets from the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7231c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Tweet into string\n",
    "daniels_tweet = \"Life like an ensemble: take the best choices from others and make your own\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fb79816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_sentence(model, sentence):\n",
    "    \"\"\"\n",
    "    Uses model to make a prediction on sentence.\n",
    "\n",
    "    Returns the sentence, the predicted label and the prediction probability.\n",
    "    \"\"\"\n",
    "    pred_prob = model.predict([sentence])\n",
    "    pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
    "    print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
    "    print(f\"Text:\\n{sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e370d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "Pred: 0.0 (not real disaster) Prob: 0.04623398184776306\n",
      "Text:\n",
      "Life like an ensemble: take the best choices from others and make your own\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction on Tweet from the wild\n",
    "predict_on_sentence(\n",
    "    model=model_6,\n",
    "    sentence=daniels_tweet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9ea8a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
    "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
    "\n",
    "# Source - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
    "beirut_tweet_2 = \"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5787390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Pred: 1.0 (real disaster) Prob: 0.9625465869903564\n",
      "Text:\n",
      "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
     ]
    }
   ],
   "source": [
    "# Predict on diaster Tweet 1\n",
    "predict_on_sentence(\n",
    "    model=model_6, \n",
    "    sentence=beirut_tweet_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1c807e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Pred: 1.0 (real disaster) Prob: 0.9678557515144348\n",
      "Text:\n",
      "#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\n"
     ]
    }
   ],
   "source": [
    "# Predict on diaster Tweet 2\n",
    "predict_on_sentence(\n",
    "    model=model_6, \n",
    "    sentence=beirut_tweet_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0805c761",
   "metadata": {},
   "source": [
    "### The speed/score tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8777b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time of predictions\n",
    "import time\n",
    "def pred_timer(model, samples):\n",
    "    \"\"\"\n",
    "    Times how long a model takes to make predictions on samples.\n",
    "  \n",
    "    Args:\n",
    "    ----\n",
    "    model = a trained model\n",
    "    sample = a list of samples\n",
    "\n",
    "    Returns:\n",
    "    ----\n",
    "    total_time = total elapsed time for model to make predictions on samples\n",
    "    time_per_pred = time in seconds per single sample\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter() # get start time\n",
    "    model.predict(samples) # make predictions\n",
    "    end_time = time.perf_counter() # get finish time\n",
    "    total_time = end_time-start_time # calculate how long predictions took to make\n",
    "    time_per_pred = total_time/len(val_sentences) # find prediction time per sample\n",
    "    return total_time, time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "627f8b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.32968926600005943, 0.0004326630787402355)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TF Hub Sentence Encoder prediction times\n",
    "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
    "model_6_total_pred_time, model_6_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "20884f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012554085005831439, 1.6475177173007138e-05)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Naive Bayes prediction times\n",
    "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
    "baseline_total_pred_time, baseline_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c36a44cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1-Score')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
    "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
    "plt.legend()\n",
    "plt.title(\"F1-score versus time per prediction\")\n",
    "plt.xlabel(\"Time per prediction\")\n",
    "plt.ylabel(\"F1-Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59697318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
