{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6b98d7",
   "metadata": {},
   "source": [
    "## Redes Neuronales - Parte I\n",
    "\n",
    "En esta actividad vamos a aprender a desarrollar nuestra propia red neuronal para reconocimiento de imagenes.\n",
    "\n",
    "Para ello, vamos a trabajar con un dataset (digits.csv) que contiene imagenes en escala de grises de 28x28 pixeles (un total de 784 pixeles). Cada imagen representa un digito (desde el 0 al 9) escrito a mano. Cada pixel tiene un valor asociado entre 0 y 255 que indica la luminosidad u oscuridad de dicho pixel (valores mas grandes indican mayor oscuridad).\n",
    "\n",
    "El dataset tiene 785 columnas, en donde la primera columna es el label del dataset y las columnas restantes son los features que indican los valores de cada pixel de la imagen.\n",
    "\n",
    "La idea es utilizar este dataset para reconocer digitos que fueron escritos manualmente utilizando una red neuronal simple. En este caso, vamos a reconocer unicamente aquellas imagenes que representen el número 2. Es decir, la idea es hacer una clasificación binaria en donde, dada una imagen de un digito escrito manualmente, se determine si corresponde con el numero 2 o no.\n",
    "\n",
    "En primer lugar, carguemos en memoria (en un pandas DataFrame) el dataset, analicemos los labels y observemos algunas imagenes.\n",
    "\n",
    "\n",
    "#### Ejercicio 1\n",
    "a) Escribir en Python un programa para dividir el dataset del archivo digits.csv almacenando los features en una variable llamada **X**  y los labels en una variable llamada **y**."
   ]
  },
  {
   "cell_type": "code",
   "id": "c828b4c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:45.341449Z",
     "start_time": "2024-04-07T02:52:43.963170Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('digits.csv')\n",
    "\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "fb5cf506",
   "metadata": {},
   "source": [
    "b) Observar la cantidad de ejemplos por cada label, analizando la variable **y**."
   ]
  },
  {
   "cell_type": "code",
   "id": "fde0f631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.221654Z",
     "start_time": "2024-04-07T02:52:45.342765Z"
    }
   },
   "source": "X.describe()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        pixel0   pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7  \\\n",
       "count  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel8   pixel9  ...      pixel774      pixel775      pixel776  \\\n",
       "count  42000.0  42000.0  ...  42000.000000  42000.000000  42000.000000   \n",
       "mean       0.0      0.0  ...      0.219286      0.117095      0.059024   \n",
       "std        0.0      0.0  ...      6.312890      4.633819      3.274488   \n",
       "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0  ...    254.000000    254.000000    253.000000   \n",
       "\n",
       "          pixel777      pixel778      pixel779  pixel780  pixel781  pixel782  \\\n",
       "count  42000.00000  42000.000000  42000.000000   42000.0   42000.0   42000.0   \n",
       "mean       0.02019      0.017238      0.002857       0.0       0.0       0.0   \n",
       "std        1.75987      1.894498      0.414264       0.0       0.0       0.0   \n",
       "min        0.00000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "25%        0.00000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "50%        0.00000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "75%        0.00000      0.000000      0.000000       0.0       0.0       0.0   \n",
       "max      253.00000    254.000000     62.000000       0.0       0.0       0.0   \n",
       "\n",
       "       pixel783  \n",
       "count   42000.0  \n",
       "mean        0.0  \n",
       "std         0.0  \n",
       "min         0.0  \n",
       "25%         0.0  \n",
       "50%         0.0  \n",
       "75%         0.0  \n",
       "max         0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.228037Z",
     "start_time": "2024-04-07T02:52:46.222552Z"
    }
   },
   "cell_type": "code",
   "source": "y.describe()",
   "id": "8e049bbeabc1bfbe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    42000.000000\n",
       "mean         4.456643\n",
       "std          2.887730\n",
       "min          0.000000\n",
       "25%          2.000000\n",
       "50%          4.000000\n",
       "75%          7.000000\n",
       "max          9.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.232480Z",
     "start_time": "2024-04-07T02:52:46.229560Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape, y.shape",
   "id": "6dfc24c2e5ad6e34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.236835Z",
     "start_time": "2024-04-07T02:52:46.233236Z"
    }
   },
   "cell_type": "code",
   "source": "y.value_counts()",
   "id": "9817b8a32ee2a146",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "fa83a0c0",
   "metadata": {},
   "source": [
    "## Visualización de imagenes del dataset\n",
    "Las imagenes (28px x 28px) fueron cargadas en memoria en un pandas Dataframe que representa un vector de 1 unica dimension (1D) con 784 valores, cada una representada por un pandas Series. Para imprimir y visualizar, como asi tambien para crear una red neuronal que las lea debemos reformatear esta estructura y convertirla en una matriz (array) de 3 dimensiones (3D) de 28x28x1. Para ello utilizamos el metodo .reshape():\n",
    "\n",
    "```\n",
    "X = X.values.reshape(-1,28,28,1)\n",
    "```\n",
    "\n",
    "**Aclaración:** el primer parametro de reshape, que se encuentra en -1, toma por defecto la dimension del array (formado por X.values que contiene todos los valores del DataFrame en un array de 2 dimensiones). Ver [documentación](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy-reshape) para más info. \n",
    "\n",
    "Tensorflow y Keras requieren una dimensión extra al final que se corresponde con los canales de colores. En este caso, las imagenes del dataset son en la escala de grises con los cual utilizaremos un unico canal (para imagenes RGB existen 3 canales)."
   ]
  },
  {
   "cell_type": "code",
   "id": "391e9537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.239500Z",
     "start_time": "2024-04-07T02:52:46.237567Z"
    }
   },
   "source": [
    "X = X.values.reshape(-1,28,28,1)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "1d27965e",
   "metadata": {},
   "source": [
    "A continuación observemos dos imagenes distintas y sus labels."
   ]
  },
  {
   "cell_type": "code",
   "id": "e336297e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.331880Z",
     "start_time": "2024-04-07T02:52:46.240231Z"
    }
   },
   "source": [
    "g1= plt.imshow(X[10][:,:,0])\n",
    "print(\"LABEL:\", y[10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a9db9860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.417605Z",
     "start_time": "2024-04-07T02:52:46.332689Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[16][:,:,0])\n",
    "print(\"LABEL:\", y[16])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "7d9829f5",
   "metadata": {},
   "source": [
    "### Redefinición de los Labels\n",
    "Como lo que queremos hacer es un clasificador binario que unicamente detecte imagenes con el valor 2, tenemos que modificar los labels para tener unicamente dos valores y=1, cuando la imagen representa un 2 e y=0, cuando la imagen representa cualquier otro digito.\n",
    "\n",
    "Para ello hacemos uso del potencial de pandas, que nos permite modificar valores de columnas facilmente utilizando condiciones y filtros. Por ejemplo, si quisieramos cambiar el valor de todos los labels que se corresponden con el digito 9 por un valor igual a -1, podemos hacer:\n",
    "\n",
    "```\n",
    "y.loc[y==9] = -1\n",
    "```\n",
    "\n",
    "Esta linea de codigo buscaria en la variable **y** (que es una pandas Series) todas aquellas filas que contienen el valor 9 y los reemplazaria con un valor igual a -1.\n",
    "\n",
    "De esta misma forma, podremos modificar nuestro dataset para que contenga dos valores y=1, para todos los labels igual a 2 e y=0 para todos los labels distintos de 2.\n",
    "\n",
    "#### Ejercicio 2\n",
    "a) Modificar los valores de **y** para que solo contenga los labels y=1 e y=0.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.421559Z",
     "start_time": "2024-04-07T02:52:46.418430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Modificar los valores de y para que solo contenga los labels y=1 e y=0.\n",
    "y.loc[y!=2] = 0\n",
    "y.loc[y==2] = 1"
   ],
   "id": "e5fcc5b8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b83657fd",
   "metadata": {},
   "source": [
    "b) Observar la cantidad de ejemplos por cada label, analizando la variable **y**."
   ]
  },
  {
   "cell_type": "code",
   "id": "3a482315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.426980Z",
     "start_time": "2024-04-07T02:52:46.423277Z"
    }
   },
   "source": "y.value_counts()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    37823\n",
       "1     4177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "535aa7e0",
   "metadata": {},
   "source": [
    "Como vimos anteriormente, para los algoritmos de ML en general suele ser mejor normalizar los datos para que el proceso de aprendizaje sea más efectivo y eficiente.\n",
    "\n",
    "Para ello normalizamos dividiendo por 255 todos los valores de pixeles que se encuentran en la variable X"
   ]
  },
  {
   "cell_type": "code",
   "id": "4374b6dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:46.479831Z",
     "start_time": "2024-04-07T02:52:46.427823Z"
    }
   },
   "source": [
    "X = X / 255.0"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "fb164b8c",
   "metadata": {},
   "source": [
    "En este punto tenemos unicamente dos labels: \n",
    "- **0**, para aquellas imagenes que no representan el digito 2\n",
    "- **1**, para las imagenes que representan el digito 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5f54b",
   "metadata": {},
   "source": [
    "### Creación del modelo con Tensorflow y Keras\n",
    "\n",
    "A continuación vamos a definir el modelo del clasificador binario. Para ello, veamos como es posible crear redes neuronales utilizando el framework Tensorflow.\n",
    "\n",
    "Lo primero que tenemos que hacer es importar el modulo de tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "id": "90a42760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:48.044255Z",
     "start_time": "2024-04-07T02:52:46.480747Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Imprimimos la version de tensorflow\n",
    "print(tf.__version__)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 23:52:46.785486: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-06 23:52:46.785507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-06 23:52:46.786124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-06 23:52:47.497125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "5dc329dc",
   "metadata": {},
   "source": [
    "En particular vamos a utilizar Keras (tf.keras), que es la API de alto nivel de TensorFlow para construir y entrenar modelos de aprendizaje profundo. \n",
    "\n",
    "Keras provee de una serie de clases que nos permiten construir facilmente redes neuronales en una pocas lineas de codigo. Veamos algunas de ellas:\n",
    "\n",
    "[Sequential](https://keras.io/api/models/sequential/): Esta clase define una secuencia de layers en la red neuronal. Suele utilizarse como contenedor de toda la red y sus layers internas.\n",
    "\n",
    "[Flatten](https://keras.io/api/layers/reshaping_layers/flatten/): En general las imágenes estan representadas por una matriz de píxeles (en este ejemplo, de 28x28). La clase Flatten simplemente toma esa matriz y la convierte en una matriz unidimensional (1D).\n",
    "\n",
    "[Dense](https://keras.io/api/layers/core_layers/dense/): La clase Dense define la layer más simple de redes neuronales en donde todas las neuronas se conectan con todas las entradas y todas las salidas.\n",
    "\n",
    "Recordemos que cada layer de neuronas necesita una [función de activación](https://keras.io/api/layers/activations/) para decirles qué hacer. Hay muchas opciones, pero por ahora solo usaremos la funcion sigmoidea ('sigmoid').\n",
    " \n",
    "Teniendo este conocimiento basico de Keras, la construcción del modelo se define de la siguiente manera:\n",
    "\n",
    "\n",
    " \n",
    "```\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layer_1)\n",
    "...\n",
    "model.add(layer_n)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "En general, si se trata de imagenes, la primera layer del modelo es de la clase Flatten. Las siguientes layers suelen ser del tipo Dense, con diferentes cantidades de neuronas. \n",
    "\n",
    "Recordemos que, como en nuestro caso estamos realizando un clasificador binario, necesitamos que la ultima layer tenga una única neurona.\n",
    "\n",
    "Ahora que sabemos como construir una red neuronal simple con Keras, vamos a definir un modelo para nuestro problema.\n",
    "\n",
    "\n",
    "#### Ejercicio 3\n",
    "a) Crear un modelo de red neuronal con Keras, usando la clase Sequential. Luego, agregarle 3 layers distintas: una layer para convertir las imagenes en una matriz 1D, una layer densa con 128 neuronas y una layer de salida tambien densa con una única neurona.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "id": "218da835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:48.559002Z",
     "start_time": "2024-04-07T02:52:48.045304Z"
    }
   },
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 23:52:48.237799: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.269766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.273747: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.277244: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.283663: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.286744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.433213: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.434752: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.436100: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-06 23:52:48.437401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6595 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "cafb62be",
   "metadata": {},
   "source": [
    "b) Compile el modelo utilizando el metodo [.compile()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile). La función de costo que vamos a utilizar es 'binary_crossentropy' y como metrica solo 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "id": "7a82f5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:52:48.571937Z",
     "start_time": "2024-04-07T02:52:48.560205Z"
    }
   },
   "source": "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "97336402",
   "metadata": {},
   "source": [
    "**c)** Entrene el modelo utilizando el método [.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), con los valores de **X** y de **y**. Setee la cantidad de epochs a 5. \n",
    "\n",
    "**Aclaración:** La cantidad de epochs se refiere al paso completo de datos de los entrenamiento a través del modelo. En este ejemplo con 5 pasadas es suficiente."
   ]
  },
  {
   "cell_type": "code",
   "id": "a42fafb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:53:00.297842Z",
     "start_time": "2024-04-07T02:52:48.572814Z"
    }
   },
   "source": "model.fit(X, y, epochs=5)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 23:52:49.209533: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-06 23:52:49.571404: I external/local_xla/xla/service/service.cc:168] XLA service 0x7d6cf845b5e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-06 23:52:49.571425: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-04-06 23:52:49.576108: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-06 23:52:49.592660: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712458369.654371   23322 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 3s 2ms/step - loss: 0.0503 - accuracy: 0.9854\n",
      "Epoch 2/5\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 3/5\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0149 - accuracy: 0.9952\n",
      "Epoch 4/5\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 5/5\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.0079 - accuracy: 0.9974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d6e002121a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "d52d467c",
   "metadata": {},
   "source": [
    "**d)** Generar predicciones para el dataset completo (**X**), utilizando el metodo [.predict()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict).\n",
    "\n",
    "**Aclaración:** Recordemos que  el metodo .predict() devuelve la probabilidad de que pertenezca a la clase positiva. En este ejemplo, sera la probabilidad de que la imagen sea efectivamente un 2."
   ]
  },
  {
   "cell_type": "code",
   "id": "7caa0816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:53:01.838678Z",
     "start_time": "2024-04-07T02:53:00.298946Z"
    }
   },
   "source": "predictions = model.predict(X)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 1s 633us/step\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "617c44f9",
   "metadata": {},
   "source": [
    "**e)** Imprimir las predicciones generadas por el modelo para las imagenes visualizadas anteriormente (indices 10 y 16). Recordemos que la imagen del indice 10 corresponde al digito 8 y la imagen del indice 16 corresponde al digito 2. En este caso, imprimir el label real y el label estimado por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "id": "55ad91bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:53:01.842720Z",
     "start_time": "2024-04-07T02:53:01.839624Z"
    }
   },
   "source": [
    "print(\"Prediccion para la imagen 10:\", predictions[10])\n",
    "print(\"Prediccion para la imagen 16:\", predictions[16])\n",
    "print(\"Label real de la imagen 10:\", y[10])\n",
    "print(\"Label real de la imagen 16:\", y[16])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediccion para la imagen 10: [4.50181e-09]\n",
      "Prediccion para la imagen 16: [0.9999995]\n",
      "Label real de la imagen 10: 0\n",
      "Label real de la imagen 16: 1\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "0c53c72f",
   "metadata": {},
   "source": [
    "Finalmente realizamos una evaluación del modelo en el dataset de entrenamiento. \n",
    "\n",
    "Tengamos en cuenta que en este ejemplo no dividimos el dataset en dataset de entrenamiento y dataset de testeo porque el objetivo era aprender a construir redes neuronales simples. Es por ello que el accuracy que arroje el metodo [.evaluate()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate) nos va a decir que tan preciso es el modelo en predecir los labels de los mismos ejemplos con los que fue entrenado. **Para evaluar con mayor precision el rendimiento del modelo deberiamos evaluarlo con un dataset desconocido por el.**\n",
    "\n",
    "\n",
    "Observar que el metodo .evaluate devuelve un vector con dos valores: el error y el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "id": "7ad944c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:53:03.463871Z",
     "start_time": "2024-04-07T02:53:01.843574Z"
    }
   },
   "source": [
    "model.evaluate(X, y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 1s 950us/step - loss: 0.0083 - accuracy: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008282090537250042, 0.9976428747177124]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "5dac43b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T02:53:03.466100Z",
     "start_time": "2024-04-07T02:53:03.464633Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
